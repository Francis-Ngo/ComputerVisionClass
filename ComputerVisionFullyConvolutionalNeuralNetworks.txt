In this video, you will learn about deep Convolutional Networks CNN’S for short In this video we will review: 1. How CNN’s Build Features 2. Adding Layers 3. Receptive Field
4. Pooling
5. Flattening and the Fully Connected Layers A convolutional network or CNN pictured here is a neural network with special layers, the model classifies an image by taking a part of the image, each input image will pass it through a series of convolution layers with filters, pooling layers, fully connected layers and while applying activation functions to classify an object. Convolution and pooling layers are the first layers used to extract features from an input these can be thought of as the feature learning layers, the fully connected layers are simply a neural network Both are learned simultaneously by minimizing the cross-entropy loss How CNN’s Build Features If you recall the H.O.G feature  used Sobel kernels to detect vertical  and horizontal edges, Looking at the kernels we see the vertical edge detector kernel looks like a vertical edge and the horizontal edge looks like a horizontal edge We can represent H.O.G with  a diagram that looks similar to a neural network, we replace the linear function with a convolution and we have the squaring and square root operations In a CNN we have neurons but the kernels are learnable parameters. The activation functions in this case RELU are applied to each pixel, instead of an activation the output is an activation map or feature map,  similar to a one channel image Like the HOG’s Sobel kernel each kernel of a CNN will detect a different property of the image, for example this activation map shows this kernel detects regions around the dogs eyes. This kernel picks up regions around the mouth, usually each output channel is smaller We use multiple kernels analogous to multiple neurons, if we have M Kernels we will have M feature maps for each map we apply the Convolution + RELU. Generally we will use clear squares to represent the feature or activation maps A grayscale image can be seen as a 1 channel input, if we have M kernels, each feature map will be a channel, therefore we will have M output channels. Adding Layers We can also stack convolutional layers each output channel is analogous to the neurons, like a neuron the input of the next layer is equal to the output of the previous layer. Here we have three outputs, the next layer will take three outputs as Inputs, if this layer has two outputs it will output two feature maps the next layer will apply a convolutional kernel to each input, then add them together, then apply an activation function. The neurons are replaced with kernels. The previous layer has three  output channels, for the first input we apply the convolution and activation to the output of the first channel, we obtain the feature map we repeat the process for the second input channel adding it to the activation map, repeating for the third input channel The process is repeated, for the next input We can process color images by having three input channels Just like a neural network we can stack layers, using the 3d representation, we can also represent them with these yellow boxes indicating the kernel size and the number of channels It’s helpful to look at the kernels to understand what the different layers are doing, if you recall the Sobel kernels looked like they detect vertical and horizontal edges they were trying to detect. Consider a CNN used to see faces, the kernels in the first layer look like edges and corners, the second layer looks like parts of the face the final layer looks like faces. We see that adding more layers builds more complex features. Receptive Field is another important factor in CNNs Receptive Field is the size of the region in the input that produces a pixel value in the activation map consider the following pixel in the following activation map, its Receptive Field is given by the larger the Receptive Field, the more information the activation map
contains about the entire image We can increase the receptive field by adding more layers, this requires less parameters then increasing the size of the kernel If we have one layer the receptive field would be the following region. Adding a second layer increases the receptive field further Pooling Pooling helps to reduce the number of parameters, increases the receptive field while preserving  the important features. To make it easier to understand, we can think about it as resizing the image. Max pooling is the most popular type of pooling. Consider the feature map. We Apply Max pooling with dimensions 2x2, it takes the maximum pixel value and we get a smaller feature map Pooling also makes CNN's more immutable to small changes in the image. We have two images they are identical but one slightly shifted let's see the activation map after max pooling, we apply max pooling in first region and repeat We see the activation map output is now identical Finally we have Flattening and the Fully Connected layers We simply flatten or reshape the output of the Feature Learning layers and use them as an input to the fully connected layers For example, if the output of the max pooling layer is 7 units of width and 7 units of height, we flatten or reshape the output, this is analogous to a feature vector this is the input to the fully connected layer each neuron has the input dimension as a flatten output for more channels we apply the similar procedure if we have 32 output channels each channel is 4x4 for a total of 16 elements as there are 32 channels multiplied by 16 we have a total of 512 elements, we flatten or reshape the output to have 512 outputs  as a result each neuron will have 512 input dimensions